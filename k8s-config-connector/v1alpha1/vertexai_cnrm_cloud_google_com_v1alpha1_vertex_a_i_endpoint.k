"""
This file was generated by the KCL auto-gen tool. DO NOT EDIT.
Editing this file might prove futile when you re-run the KCL auto-gen generate command.
"""
import k8s.apimachinery.pkg.apis.meta.v1


schema VertexAIEndpoint:
    """
    vertexai cnrm cloud google com v1alpha1 vertex a i endpoint

    Attributes
    ----------
    apiVersion : str, default is "vertexai.cnrm.cloud.google.com/v1alpha1", required
        APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
    kind : str, default is "VertexAIEndpoint", required
        Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
    metadata : v1.ObjectMeta, default is Undefined, optional
        metadata
    spec : VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointSpec, default is Undefined, required
        spec
    status : VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatus, default is Undefined, optional
        status
    """


    apiVersion: "vertexai.cnrm.cloud.google.com/v1alpha1" = "vertexai.cnrm.cloud.google.com/v1alpha1"

    kind: "VertexAIEndpoint" = "VertexAIEndpoint"

    metadata?: v1.ObjectMeta

    spec: VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointSpec

    status?: VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatus


schema VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointSpec:
    """
    vertexai cnrm cloud google com v1alpha1 vertex a i endpoint spec

    Attributes
    ----------
    description : str, default is Undefined, optional
        The description of the Endpoint.
    displayName : str, default is Undefined, required
        Required. The display name of the Endpoint. The name can be up to 128 characters long and can consist of any UTF-8 characters.
    encryptionSpec : VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointSpecEncryptionSpec, default is Undefined, optional
        encryption spec
    location : str, default is Undefined, required
        Immutable. The location for the resource.
    network : str, default is Undefined, optional
        Immutable. The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks) to which the Endpoint should be peered. Private services access must already be configured for the network. If left unspecified, the Endpoint is not peered with any network. Only one of the fields, network or enable_private_service_connect, can be set. [Format](https://cloud.google.com/compute/docs/reference/rest/v1/networks/insert): 'projects/{project}/global/networks/{network}'. Where '{project}' is a project number, as in '12345', and '{network}' is network name.
    projectRef : VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointSpecProjectRef, default is Undefined, required
        project ref
    region : str, default is Undefined, optional
        Immutable. The region for the resource.
    resourceID : str, default is Undefined, optional
        Immutable. Optional. The name of the resource. Used for creation and acquisition. When unset, the value of `metadata.name` is used as the default.
    """


    description?: str

    displayName: str

    encryptionSpec?: VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointSpecEncryptionSpec

    location: str

    network?: str

    projectRef: VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointSpecProjectRef

    region?: str

    resourceID?: str


schema VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointSpecEncryptionSpec:
    """
    Immutable. Customer-managed encryption key spec for an Endpoint. If set, this Endpoint and all sub-resources of this Endpoint will be secured by this key.

    Attributes
    ----------
    kmsKeyName : str, default is Undefined, required
        Immutable. Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: 'projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key'. The key needs to be in the same region as where the compute resource is created.
    """


    kmsKeyName: str


schema VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointSpecProjectRef:
    """
    The project that this resource belongs to.

    Attributes
    ----------
    external : str, default is Undefined, optional
        Allowed value: The `name` field of a `Project` resource.
    name : str, default is Undefined, optional
        Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names
    namespace : str, default is Undefined, optional
        Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/
    """


    external?: str

    name?: str

    namespace?: str


schema VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatus:
    """
    vertexai cnrm cloud google com v1alpha1 vertex a i endpoint status

    Attributes
    ----------
    conditions : [VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusConditionsItems0], default is Undefined, optional
        Conditions represent the latest available observation of the resource's current state.
    createTime : str, default is Undefined, optional
        Output only. Timestamp when this Endpoint was created.
    deployedModels : [VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusDeployedModelsItems0], default is Undefined, optional
        Output only. The models deployed in this Endpoint. To add or remove DeployedModels use EndpointService.DeployModel and EndpointService.UndeployModel respectively. Models can also be deployed and undeployed using the [Cloud Console](https://console.cloud.google.com/vertex-ai/).
    etag : str, default is Undefined, optional
        Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
    modelDeploymentMonitoringJob : str, default is Undefined, optional
        Output only. Resource name of the Model Monitoring job associated with this Endpoint if monitoring is enabled by CreateModelDeploymentMonitoringJob. Format: 'projects/{project}/locations/{location}/modelDeploymentMonitoringJobs/{model_deployment_monitoring_job}'.
    observedGeneration : int, default is Undefined, optional
        ObservedGeneration is the generation of the resource that was most recently observed by the Config Connector controller. If this is equal to metadata.generation, then that means that the current reported status reflects the most recent desired state of the resource.
    updateTime : str, default is Undefined, optional
        Output only. Timestamp when this Endpoint was last updated.
    """


    conditions?: [VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusConditionsItems0]

    createTime?: str

    deployedModels?: [VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusDeployedModelsItems0]

    etag?: str

    modelDeploymentMonitoringJob?: str

    observedGeneration?: int

    updateTime?: str


schema VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusConditionsItems0:
    """
    vertexai cnrm cloud google com v1alpha1 vertex a i endpoint status conditions items0

    Attributes
    ----------
    lastTransitionTime : str, default is Undefined, optional
        Last time the condition transitioned from one status to another.
    message : str, default is Undefined, optional
        Human-readable message indicating details about last transition.
    reason : str, default is Undefined, optional
        Unique, one-word, CamelCase reason for the condition's last transition.
    status : str, default is Undefined, optional
        Status is the status of the condition. Can be True, False, Unknown.
    $type : str, default is Undefined, optional
        Type is the type of the condition.
    """


    lastTransitionTime?: str

    message?: str

    reason?: str

    status?: str

    $type?: str


schema VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusDeployedModelsItems0:
    """
    vertexai cnrm cloud google com v1alpha1 vertex a i endpoint status deployed models items0

    Attributes
    ----------
    automaticResources : [VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusDeployedModelsItems0AutomaticResourcesItems0], default is Undefined, optional
        A description of resources that to large degree are decided by Vertex AI, and require only a modest additional configuration.
    createTime : str, default is Undefined, optional
        Output only. Timestamp when the DeployedModel was created.
    dedicatedResources : [VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusDeployedModelsItems0DedicatedResourcesItems0], default is Undefined, optional
        A description of resources that are dedicated to the DeployedModel, and that need a higher degree of manual configuration.
    displayName : str, default is Undefined, optional
        The display name of the DeployedModel. If not provided upon creation, the Model's display_name is used.
    enableAccessLogging : bool, default is Undefined, optional
        These logs are like standard server access logs, containing information like timestamp and latency for each prediction request. Note that Stackdriver logs may incur a cost, especially if your project receives prediction requests at a high queries per second rate (QPS). Estimate your costs before enabling this option.
    enableContainerLogging : bool, default is Undefined, optional
        If true, the container of the DeployedModel instances will send 'stderr' and 'stdout' streams to Stackdriver Logging. Only supported for custom-trained Models and AutoML Tabular Models.
    id : str, default is Undefined, optional
        The ID of the DeployedModel. If not provided upon deployment, Vertex AI will generate a value for this ID. This value should be 1-10 characters, and valid characters are /[0-9]/.
    model : str, default is Undefined, optional
        The name of the Model that this is the deployment of. Note that the Model may be in a different location than the DeployedModel's Endpoint.
    modelVersionId : str, default is Undefined, optional
        Output only. The version ID of the model that is deployed.
    privateEndpoints : [VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusDeployedModelsItems0PrivateEndpointsItems0], default is Undefined, optional
        Output only. Provide paths for users to send predict/explain/health requests directly to the deployed model services running on Cloud via private services access. This field is populated if network is configured.
    serviceAccount : str, default is Undefined, optional
        The service account that the DeployedModel's container runs as. Specify the email address of the service account. If this service account is not specified, the container runs as a service account that doesn't have access to the resource project. Users deploying the Model must have the 'iam.serviceAccounts.actAs' permission on this service account.
    sharedResources : str, default is Undefined, optional
        The resource name of the shared DeploymentResourcePool to deploy on. Format: projects/{project}/locations/{location}/deploymentResourcePools/{deployment_resource_pool}.
    """


    automaticResources?: [VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusDeployedModelsItems0AutomaticResourcesItems0]

    createTime?: str

    dedicatedResources?: [VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusDeployedModelsItems0DedicatedResourcesItems0]

    displayName?: str

    enableAccessLogging?: bool

    enableContainerLogging?: bool

    id?: str

    model?: str

    modelVersionId?: str

    privateEndpoints?: [VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusDeployedModelsItems0PrivateEndpointsItems0]

    serviceAccount?: str

    sharedResources?: str


schema VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusDeployedModelsItems0AutomaticResourcesItems0:
    """
    vertexai cnrm cloud google com v1alpha1 vertex a i endpoint status deployed models items0 automatic resources items0

    Attributes
    ----------
    maxReplicaCount : int, default is Undefined, optional
        The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
    minReplicaCount : int, default is Undefined, optional
        The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
    """


    maxReplicaCount?: int

    minReplicaCount?: int


schema VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusDeployedModelsItems0DedicatedResourcesItems0:
    """
    vertexai cnrm cloud google com v1alpha1 vertex a i endpoint status deployed models items0 dedicated resources items0

    Attributes
    ----------
    autoscalingMetricSpecs : [VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusDeployedModelsItems0DedicatedResourcesItems0AutoscalingMetricSpecsItems0], default is Undefined, optional
        The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to 'aiplatform.googleapis.com/prediction/online/cpu/utilization' and autoscaling_metric_specs.target to '80'.
    machineSpec : [VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusDeployedModelsItems0DedicatedResourcesItems0MachineSpecItems0], default is Undefined, optional
        The specification of a single machine used by the prediction.
    maxReplicaCount : int, default is Undefined, optional
        The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use min_replica_count as the default value. The value of this field impacts the charge against Vertex CPU and GPU quotas. Specifically, you will be charged for max_replica_count * number of cores in the selected machine type) and (max_replica_count * number of GPUs per replica in the selected machine type).
    minReplicaCount : int, default is Undefined, optional
        The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1. If traffic against the DeployedModel increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.
    """


    autoscalingMetricSpecs?: [VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusDeployedModelsItems0DedicatedResourcesItems0AutoscalingMetricSpecsItems0]

    machineSpec?: [VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusDeployedModelsItems0DedicatedResourcesItems0MachineSpecItems0]

    maxReplicaCount?: int

    minReplicaCount?: int


schema VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusDeployedModelsItems0DedicatedResourcesItems0AutoscalingMetricSpecsItems0:
    """
    vertexai cnrm cloud google com v1alpha1 vertex a i endpoint status deployed models items0 dedicated resources items0 autoscaling metric specs items0

    Attributes
    ----------
    metricName : str, default is Undefined, optional
        The resource metric name. Supported metrics: * For Online Prediction: * 'aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle' * 'aiplatform.googleapis.com/prediction/online/cpu/utilization'.
    target : int, default is Undefined, optional
        The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
    """


    metricName?: str

    target?: int


schema VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusDeployedModelsItems0DedicatedResourcesItems0MachineSpecItems0:
    """
    vertexai cnrm cloud google com v1alpha1 vertex a i endpoint status deployed models items0 dedicated resources items0 machine spec items0

    Attributes
    ----------
    acceleratorCount : int, default is Undefined, optional
        The number of accelerators to attach to the machine.
    acceleratorType : str, default is Undefined, optional
        The type of accelerator(s) that may be attached to the machine as per accelerator_count. See possible values [here](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec#AcceleratorType).
    machineType : str, default is Undefined, optional
        The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is 'n1-standard-2'. For BatchPredictionJob or as part of WorkerPoolSpec this field is required. TODO(rsurowka): Try to better unify the required vs optional.
    """


    acceleratorCount?: int

    acceleratorType?: str

    machineType?: str


schema VertexaiCnrmCloudGoogleComV1alpha1VertexAIEndpointStatusDeployedModelsItems0PrivateEndpointsItems0:
    """
    vertexai cnrm cloud google com v1alpha1 vertex a i endpoint status deployed models items0 private endpoints items0

    Attributes
    ----------
    explainHttpUri : str, default is Undefined, optional
        Output only. Http(s) path to send explain requests.
    healthHttpUri : str, default is Undefined, optional
        Output only. Http(s) path to send health check requests.
    predictHttpUri : str, default is Undefined, optional
        Output only. Http(s) path to send prediction requests.
    serviceAttachment : str, default is Undefined, optional
        Output only. The name of the service attachment resource. Populated if private service connect is enabled.
    """


    explainHttpUri?: str

    healthHttpUri?: str

    predictHttpUri?: str

    serviceAttachment?: str


