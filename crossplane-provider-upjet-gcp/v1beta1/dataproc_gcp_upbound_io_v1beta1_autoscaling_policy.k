"""
This file was generated by the KCL auto-gen tool. DO NOT EDIT.
Editing this file might prove futile when you re-run the KCL auto-gen generate command.
"""
import k8s.apimachinery.pkg.apis.meta.v1


schema AutoscalingPolicy:
    """
    AutoscalingPolicy is the Schema for the AutoscalingPolicys API. Describes an autoscaling policy for Dataproc cluster autoscaler.

    Attributes
    ----------
    apiVersion : str, default is "dataproc.gcp.upbound.io/v1beta1", required
        APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
    kind : str, default is "AutoscalingPolicy", required
        Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
    metadata : v1.ObjectMeta, default is Undefined, optional
        metadata
    spec : DataprocGcpUpboundIoV1beta1AutoscalingPolicySpec, default is Undefined, required
        spec
    status : DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatus, default is Undefined, optional
        status
    """


    apiVersion: "dataproc.gcp.upbound.io/v1beta1" = "dataproc.gcp.upbound.io/v1beta1"

    kind: "AutoscalingPolicy" = "AutoscalingPolicy"

    metadata?: v1.ObjectMeta

    spec: DataprocGcpUpboundIoV1beta1AutoscalingPolicySpec

    status?: DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatus


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicySpec:
    """
    AutoscalingPolicySpec defines the desired state of AutoscalingPolicy

    Attributes
    ----------
    deletionPolicy : str, default is "Delete", optional
        DeletionPolicy specifies what will happen to the underlying external
        when this managed resource is deleted - either "Delete" or "Orphan" the
        external resource.
        This field is planned to be deprecated in favor of the ManagementPolicies
        field in a future release. Currently, both could be set independently and
        non-default values would be honored if the feature flag is enabled.
        See the design doc for more information: https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223
    forProvider : DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecForProvider, default is Undefined, required
        for provider
    initProvider : DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecInitProvider, default is Undefined, optional
        init provider
    managementPolicies : [str], default is ["*"], optional
        THIS IS A BETA FIELD. It is on by default but can be opted out
        through a Crossplane feature flag.
        ManagementPolicies specify the array of actions Crossplane is allowed to
        take on the managed and external resources.
        This field is planned to replace the DeletionPolicy field in a future
        release. Currently, both could be set independently and non-default
        values would be honored if the feature flag is enabled. If both are
        custom, the DeletionPolicy field will be ignored.
        See the design doc for more information: https://github.com/crossplane/crossplane/blob/499895a25d1a1a0ba1604944ef98ac7a1a71f197/design/design-doc-observe-only-resources.md?plain=1#L223
        and this one: https://github.com/crossplane/crossplane/blob/444267e84783136daa93568b364a5f01228cacbe/design/one-pager-ignore-changes.md
    providerConfigRef : DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecProviderConfigRef, default is Undefined, optional
        provider config ref
    publishConnectionDetailsTo : DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecPublishConnectionDetailsTo, default is Undefined, optional
        publish connection details to
    writeConnectionSecretToRef : DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecWriteConnectionSecretToRef, default is Undefined, optional
        write connection secret to ref
    """


    deletionPolicy?: "Orphan" | "Delete" = "Delete"

    forProvider: DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecForProvider

    initProvider?: DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecInitProvider

    managementPolicies?: [str] = ["*"]

    providerConfigRef?: DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecProviderConfigRef

    publishConnectionDetailsTo?: DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecPublishConnectionDetailsTo

    writeConnectionSecretToRef?: DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecWriteConnectionSecretToRef


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecForProvider:
    """
    dataproc gcp upbound io v1beta1 autoscaling policy spec for provider

    Attributes
    ----------
    basicAlgorithm : [DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecForProviderBasicAlgorithmItems0], default is Undefined, optional
        Basic algorithm for autoscaling.
        Structure is documented below.
    location : str, default is Undefined, optional
        The  location where the autoscaling policy should reside.
        The default value is global.
    project : str, default is Undefined, optional
        The ID of the project in which the resource belongs.
        If it is not provided, the provider project is used.
    secondaryWorkerConfig : [DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecForProviderSecondaryWorkerConfigItems0], default is Undefined, optional
        Describes how the autoscaler will operate for secondary workers.
        Structure is documented below.
    workerConfig : [DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecForProviderWorkerConfigItems0], default is Undefined, optional
        Describes how the autoscaler will operate for primary workers.
        Structure is documented below.
    """


    basicAlgorithm?: [DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecForProviderBasicAlgorithmItems0]

    location?: str

    project?: str

    secondaryWorkerConfig?: [DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecForProviderSecondaryWorkerConfigItems0]

    workerConfig?: [DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecForProviderWorkerConfigItems0]


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecForProviderBasicAlgorithmItems0:
    """
    dataproc gcp upbound io v1beta1 autoscaling policy spec for provider basic algorithm items0

    Attributes
    ----------
    cooldownPeriod : str, default is Undefined, optional
        Duration between scaling events. A scaling period starts after the
        update operation from the previous event has completed.
        Bounds: [2m, 1d]. Default: 2m.
    yarnConfig : [DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecForProviderBasicAlgorithmItems0YarnConfigItems0], default is Undefined, optional
        YARN autoscaling configuration.
        Structure is documented below.
    """


    cooldownPeriod?: str

    yarnConfig?: [DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecForProviderBasicAlgorithmItems0YarnConfigItems0]


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecForProviderBasicAlgorithmItems0YarnConfigItems0:
    """
    dataproc gcp upbound io v1beta1 autoscaling policy spec for provider basic algorithm items0 yarn config items0

    Attributes
    ----------
    gracefulDecommissionTimeout : str, default is Undefined, optional
        Timeout for YARN graceful decommissioning of Node Managers. Specifies the
        duration to wait for jobs to complete before forcefully removing workers
        (and potentially interrupting jobs). Only applicable to downscaling operations.
        Bounds: [0s, 1d].
    scaleDownFactor : float, default is Undefined, optional
        Fraction of average pending memory in the last cooldown period for which to
        remove workers. A scale-down factor of 1 will result in scaling down so that there
        is no available memory remaining after the update (more aggressive scaling).
        A scale-down factor of 0 disables removing workers, which can be beneficial for
        autoscaling a single job.
        Bounds: [0.0, 1.0].
    scaleDownMinWorkerFraction : float, default is Undefined, optional
        Minimum scale-down threshold as a fraction of total cluster size before scaling occurs.
        For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler must
        recommend at least a 2 worker scale-down for the cluster to scale. A threshold of 0
        means the autoscaler will scale down on any recommended change.
        Bounds: [0.0, 1.0]. Default: 0.0.
    scaleUpFactor : float, default is Undefined, optional
        Fraction of average pending memory in the last cooldown period for which to
        add workers. A scale-up factor of 1.0 will result in scaling up so that there
        is no pending memory remaining after the update (more aggressive scaling).
        A scale-up factor closer to 0 will result in a smaller magnitude of scaling up
        (less aggressive scaling).
        Bounds: [0.0, 1.0].
    scaleUpMinWorkerFraction : float, default is Undefined, optional
        Minimum scale-up threshold as a fraction of total cluster size before scaling
        occurs. For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler
        must recommend at least a 2-worker scale-up for the cluster to scale. A threshold of
        0 means the autoscaler will scale up on any recommended change.
        Bounds: [0.0, 1.0]. Default: 0.0.
    """


    gracefulDecommissionTimeout?: str

    scaleDownFactor?: float

    scaleDownMinWorkerFraction?: float

    scaleUpFactor?: float

    scaleUpMinWorkerFraction?: float


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecForProviderSecondaryWorkerConfigItems0:
    """
    dataproc gcp upbound io v1beta1 autoscaling policy spec for provider secondary worker config items0

    Attributes
    ----------
    maxInstances : float, default is Undefined, optional
        Maximum number of instances for this group. Note that by default, clusters will not use
        secondary workers. Required for secondary workers if the minimum secondary instances is set.
        Bounds: [minInstances, ). Defaults to 0.
    minInstances : float, default is Undefined, optional
        Minimum number of instances for this group. Bounds: [0, maxInstances]. Defaults to 0.
    weight : float, default is Undefined, optional
        Weight for the instance group, which is used to determine the fraction of total workers
        in the cluster from this instance group. For example, if primary workers have weight 2,
        and secondary workers have weight 1, the cluster will have approximately 2 primary workers
        for each secondary worker.
        The cluster may not reach the specified balance if constrained by min/max bounds or other
        autoscaling settings. For example, if maxInstances for secondary workers is 0, then only
        primary workers will be added. The cluster can also be out of balance when created.
        If weight is not set on any instance group, the cluster will default to equal weight for
        all groups: the cluster will attempt to maintain an equal number of workers in each group
        within the configured size bounds for each group. If weight is set for one group only,
        the cluster will default to zero weight on the unset group. For example if weight is set
        only on primary workers, the cluster will use primary workers only and no secondary workers.
    """


    maxInstances?: float

    minInstances?: float

    weight?: float


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecForProviderWorkerConfigItems0:
    """
    dataproc gcp upbound io v1beta1 autoscaling policy spec for provider worker config items0

    Attributes
    ----------
    maxInstances : float, default is Undefined, optional
        Maximum number of instances for this group.
    minInstances : float, default is Undefined, optional
        Minimum number of instances for this group. Bounds: [2, maxInstances]. Defaults to 2.
    weight : float, default is Undefined, optional
        Weight for the instance group, which is used to determine the fraction of total workers
        in the cluster from this instance group. For example, if primary workers have weight 2,
        and secondary workers have weight 1, the cluster will have approximately 2 primary workers
        for each secondary worker.
        The cluster may not reach the specified balance if constrained by min/max bounds or other
        autoscaling settings. For example, if maxInstances for secondary workers is 0, then only
        primary workers will be added. The cluster can also be out of balance when created.
        If weight is not set on any instance group, the cluster will default to equal weight for
        all groups: the cluster will attempt to maintain an equal number of workers in each group
        within the configured size bounds for each group. If weight is set for one group only,
        the cluster will default to zero weight on the unset group. For example if weight is set
        only on primary workers, the cluster will use primary workers only and no secondary workers.
    """


    maxInstances?: float

    minInstances?: float

    weight?: float


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecInitProvider:
    """
    THIS IS A BETA FIELD. It will be honored
    unless the Management Policies feature flag is disabled.
    InitProvider holds the same fields as ForProvider, with the exception
    of Identifier and other resource reference fields. The fields that are
    in InitProvider are merged into ForProvider when the resource is created.
    The same fields are also added to the terraform ignore_changes hook, to
    avoid updating them after creation. This is useful for fields that are
    required on creation, but we do not desire to update them after creation,
    for example because of an external controller is managing them, like an
    autoscaler.

    Attributes
    ----------
    basicAlgorithm : [DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecInitProviderBasicAlgorithmItems0], default is Undefined, optional
        Basic algorithm for autoscaling.
        Structure is documented below.
    project : str, default is Undefined, optional
        The ID of the project in which the resource belongs.
        If it is not provided, the provider project is used.
    secondaryWorkerConfig : [DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecInitProviderSecondaryWorkerConfigItems0], default is Undefined, optional
        Describes how the autoscaler will operate for secondary workers.
        Structure is documented below.
    workerConfig : [DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecInitProviderWorkerConfigItems0], default is Undefined, optional
        Describes how the autoscaler will operate for primary workers.
        Structure is documented below.
    """


    basicAlgorithm?: [DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecInitProviderBasicAlgorithmItems0]

    project?: str

    secondaryWorkerConfig?: [DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecInitProviderSecondaryWorkerConfigItems0]

    workerConfig?: [DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecInitProviderWorkerConfigItems0]


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecInitProviderBasicAlgorithmItems0:
    """
    dataproc gcp upbound io v1beta1 autoscaling policy spec init provider basic algorithm items0

    Attributes
    ----------
    cooldownPeriod : str, default is Undefined, optional
        Duration between scaling events. A scaling period starts after the
        update operation from the previous event has completed.
        Bounds: [2m, 1d]. Default: 2m.
    yarnConfig : [DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecInitProviderBasicAlgorithmItems0YarnConfigItems0], default is Undefined, optional
        YARN autoscaling configuration.
        Structure is documented below.
    """


    cooldownPeriod?: str

    yarnConfig?: [DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecInitProviderBasicAlgorithmItems0YarnConfigItems0]


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecInitProviderBasicAlgorithmItems0YarnConfigItems0:
    """
    dataproc gcp upbound io v1beta1 autoscaling policy spec init provider basic algorithm items0 yarn config items0

    Attributes
    ----------
    gracefulDecommissionTimeout : str, default is Undefined, optional
        Timeout for YARN graceful decommissioning of Node Managers. Specifies the
        duration to wait for jobs to complete before forcefully removing workers
        (and potentially interrupting jobs). Only applicable to downscaling operations.
        Bounds: [0s, 1d].
    scaleDownFactor : float, default is Undefined, optional
        Fraction of average pending memory in the last cooldown period for which to
        remove workers. A scale-down factor of 1 will result in scaling down so that there
        is no available memory remaining after the update (more aggressive scaling).
        A scale-down factor of 0 disables removing workers, which can be beneficial for
        autoscaling a single job.
        Bounds: [0.0, 1.0].
    scaleDownMinWorkerFraction : float, default is Undefined, optional
        Minimum scale-down threshold as a fraction of total cluster size before scaling occurs.
        For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler must
        recommend at least a 2 worker scale-down for the cluster to scale. A threshold of 0
        means the autoscaler will scale down on any recommended change.
        Bounds: [0.0, 1.0]. Default: 0.0.
    scaleUpFactor : float, default is Undefined, optional
        Fraction of average pending memory in the last cooldown period for which to
        add workers. A scale-up factor of 1.0 will result in scaling up so that there
        is no pending memory remaining after the update (more aggressive scaling).
        A scale-up factor closer to 0 will result in a smaller magnitude of scaling up
        (less aggressive scaling).
        Bounds: [0.0, 1.0].
    scaleUpMinWorkerFraction : float, default is Undefined, optional
        Minimum scale-up threshold as a fraction of total cluster size before scaling
        occurs. For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler
        must recommend at least a 2-worker scale-up for the cluster to scale. A threshold of
        0 means the autoscaler will scale up on any recommended change.
        Bounds: [0.0, 1.0]. Default: 0.0.
    """


    gracefulDecommissionTimeout?: str

    scaleDownFactor?: float

    scaleDownMinWorkerFraction?: float

    scaleUpFactor?: float

    scaleUpMinWorkerFraction?: float


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecInitProviderSecondaryWorkerConfigItems0:
    """
    dataproc gcp upbound io v1beta1 autoscaling policy spec init provider secondary worker config items0

    Attributes
    ----------
    maxInstances : float, default is Undefined, optional
        Maximum number of instances for this group. Note that by default, clusters will not use
        secondary workers. Required for secondary workers if the minimum secondary instances is set.
        Bounds: [minInstances, ). Defaults to 0.
    minInstances : float, default is Undefined, optional
        Minimum number of instances for this group. Bounds: [0, maxInstances]. Defaults to 0.
    weight : float, default is Undefined, optional
        Weight for the instance group, which is used to determine the fraction of total workers
        in the cluster from this instance group. For example, if primary workers have weight 2,
        and secondary workers have weight 1, the cluster will have approximately 2 primary workers
        for each secondary worker.
        The cluster may not reach the specified balance if constrained by min/max bounds or other
        autoscaling settings. For example, if maxInstances for secondary workers is 0, then only
        primary workers will be added. The cluster can also be out of balance when created.
        If weight is not set on any instance group, the cluster will default to equal weight for
        all groups: the cluster will attempt to maintain an equal number of workers in each group
        within the configured size bounds for each group. If weight is set for one group only,
        the cluster will default to zero weight on the unset group. For example if weight is set
        only on primary workers, the cluster will use primary workers only and no secondary workers.
    """


    maxInstances?: float

    minInstances?: float

    weight?: float


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecInitProviderWorkerConfigItems0:
    """
    dataproc gcp upbound io v1beta1 autoscaling policy spec init provider worker config items0

    Attributes
    ----------
    maxInstances : float, default is Undefined, optional
        Maximum number of instances for this group.
    minInstances : float, default is Undefined, optional
        Minimum number of instances for this group. Bounds: [2, maxInstances]. Defaults to 2.
    weight : float, default is Undefined, optional
        Weight for the instance group, which is used to determine the fraction of total workers
        in the cluster from this instance group. For example, if primary workers have weight 2,
        and secondary workers have weight 1, the cluster will have approximately 2 primary workers
        for each secondary worker.
        The cluster may not reach the specified balance if constrained by min/max bounds or other
        autoscaling settings. For example, if maxInstances for secondary workers is 0, then only
        primary workers will be added. The cluster can also be out of balance when created.
        If weight is not set on any instance group, the cluster will default to equal weight for
        all groups: the cluster will attempt to maintain an equal number of workers in each group
        within the configured size bounds for each group. If weight is set for one group only,
        the cluster will default to zero weight on the unset group. For example if weight is set
        only on primary workers, the cluster will use primary workers only and no secondary workers.
    """


    maxInstances?: float

    minInstances?: float

    weight?: float


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecProviderConfigRef:
    """
    ProviderConfigReference specifies how the provider that will be used to
    create, observe, update, and delete this managed resource should be
    configured.

    Attributes
    ----------
    name : str, default is Undefined, required
        Name of the referenced object.
    policy : DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecProviderConfigRefPolicy, default is Undefined, optional
        policy
    """


    name: str

    policy?: DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecProviderConfigRefPolicy


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecProviderConfigRefPolicy:
    """
    Policies for referencing.

    Attributes
    ----------
    resolution : str, default is "Required", optional
        Resolution specifies whether resolution of this reference is required.
        The default is 'Required', which means the reconcile will fail if the
        reference cannot be resolved. 'Optional' means this reference will be
        a no-op if it cannot be resolved.
    resolve : str, default is Undefined, optional
        Resolve specifies when this reference should be resolved. The default
        is 'IfNotPresent', which will attempt to resolve the reference only when
        the corresponding field is not present. Use 'Always' to resolve the
        reference on every reconcile.
    """


    resolution?: "Required" | "Optional" = "Required"

    resolve?: "Always" | "IfNotPresent"


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecPublishConnectionDetailsTo:
    """
    PublishConnectionDetailsTo specifies the connection secret config which
    contains a name, metadata and a reference to secret store config to
    which any connection details for this managed resource should be written.
    Connection details frequently include the endpoint, username,
    and password required to connect to the managed resource.

    Attributes
    ----------
    configRef : DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecPublishConnectionDetailsToConfigRef, default is Undefined, optional
        config ref
    metadata : DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecPublishConnectionDetailsToMetadata, default is Undefined, optional
        metadata
    name : str, default is Undefined, required
        Name is the name of the connection secret.
    """


    configRef?: DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecPublishConnectionDetailsToConfigRef

    metadata?: DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecPublishConnectionDetailsToMetadata

    name: str


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecPublishConnectionDetailsToConfigRef:
    """
    SecretStoreConfigRef specifies which secret store config should be used
    for this ConnectionSecret.

    Attributes
    ----------
    name : str, default is Undefined, required
        Name of the referenced object.
    policy : DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecPublishConnectionDetailsToConfigRefPolicy, default is Undefined, optional
        policy
    """


    name: str

    policy?: DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecPublishConnectionDetailsToConfigRefPolicy


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecPublishConnectionDetailsToConfigRefPolicy:
    """
    Policies for referencing.

    Attributes
    ----------
    resolution : str, default is "Required", optional
        Resolution specifies whether resolution of this reference is required.
        The default is 'Required', which means the reconcile will fail if the
        reference cannot be resolved. 'Optional' means this reference will be
        a no-op if it cannot be resolved.
    resolve : str, default is Undefined, optional
        Resolve specifies when this reference should be resolved. The default
        is 'IfNotPresent', which will attempt to resolve the reference only when
        the corresponding field is not present. Use 'Always' to resolve the
        reference on every reconcile.
    """


    resolution?: "Required" | "Optional" = "Required"

    resolve?: "Always" | "IfNotPresent"


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecPublishConnectionDetailsToMetadata:
    """
    Metadata is the metadata for connection secret.

    Attributes
    ----------
    annotations : {str:str}, default is Undefined, optional
        Annotations are the annotations to be added to connection secret.
        - For Kubernetes secrets, this will be used as "metadata.annotations".
        - It is up to Secret Store implementation for others store types.
    labels : {str:str}, default is Undefined, optional
        Labels are the labels/tags to be added to connection secret.
        - For Kubernetes secrets, this will be used as "metadata.labels".
        - It is up to Secret Store implementation for others store types.
    $type : str, default is Undefined, optional
        Type is the SecretType for the connection secret.
        - Only valid for Kubernetes Secret Stores.
    """


    annotations?: {str:str}

    labels?: {str:str}

    $type?: str


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicySpecWriteConnectionSecretToRef:
    """
    WriteConnectionSecretToReference specifies the namespace and name of a
    Secret to which any connection details for this managed resource should
    be written. Connection details frequently include the endpoint, username,
    and password required to connect to the managed resource.
    This field is planned to be replaced in a future release in favor of
    PublishConnectionDetailsTo. Currently, both could be set independently
    and connection details would be published to both without affecting
    each other.

    Attributes
    ----------
    name : str, default is Undefined, required
        Name of the secret.
    namespace : str, default is Undefined, required
        Namespace of the secret.
    """


    name: str

    namespace: str


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatus:
    """
    AutoscalingPolicyStatus defines the observed state of AutoscalingPolicy.

    Attributes
    ----------
    atProvider : DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatusAtProvider, default is Undefined, optional
        at provider
    conditions : [DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatusConditionsItems0], default is Undefined, optional
        Conditions of the resource.
    """


    atProvider?: DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatusAtProvider

    conditions?: [DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatusConditionsItems0]


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatusAtProvider:
    """
    dataproc gcp upbound io v1beta1 autoscaling policy status at provider

    Attributes
    ----------
    basicAlgorithm : [DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatusAtProviderBasicAlgorithmItems0], default is Undefined, optional
        Basic algorithm for autoscaling.
        Structure is documented below.
    id : str, default is Undefined, optional
        an identifier for the resource with format projects/{{project}}/locations/{{location}}/autoscalingPolicies/{{policy_id}}
    location : str, default is Undefined, optional
        The  location where the autoscaling policy should reside.
        The default value is global.
    name : str, default is Undefined, optional
        The "resource name" of the autoscaling policy.
    project : str, default is Undefined, optional
        The ID of the project in which the resource belongs.
        If it is not provided, the provider project is used.
    secondaryWorkerConfig : [DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatusAtProviderSecondaryWorkerConfigItems0], default is Undefined, optional
        Describes how the autoscaler will operate for secondary workers.
        Structure is documented below.
    workerConfig : [DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatusAtProviderWorkerConfigItems0], default is Undefined, optional
        Describes how the autoscaler will operate for primary workers.
        Structure is documented below.
    """


    basicAlgorithm?: [DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatusAtProviderBasicAlgorithmItems0]

    id?: str

    location?: str

    name?: str

    project?: str

    secondaryWorkerConfig?: [DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatusAtProviderSecondaryWorkerConfigItems0]

    workerConfig?: [DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatusAtProviderWorkerConfigItems0]


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatusAtProviderBasicAlgorithmItems0:
    """
    dataproc gcp upbound io v1beta1 autoscaling policy status at provider basic algorithm items0

    Attributes
    ----------
    cooldownPeriod : str, default is Undefined, optional
        Duration between scaling events. A scaling period starts after the
        update operation from the previous event has completed.
        Bounds: [2m, 1d]. Default: 2m.
    yarnConfig : [DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatusAtProviderBasicAlgorithmItems0YarnConfigItems0], default is Undefined, optional
        YARN autoscaling configuration.
        Structure is documented below.
    """


    cooldownPeriod?: str

    yarnConfig?: [DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatusAtProviderBasicAlgorithmItems0YarnConfigItems0]


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatusAtProviderBasicAlgorithmItems0YarnConfigItems0:
    """
    dataproc gcp upbound io v1beta1 autoscaling policy status at provider basic algorithm items0 yarn config items0

    Attributes
    ----------
    gracefulDecommissionTimeout : str, default is Undefined, optional
        Timeout for YARN graceful decommissioning of Node Managers. Specifies the
        duration to wait for jobs to complete before forcefully removing workers
        (and potentially interrupting jobs). Only applicable to downscaling operations.
        Bounds: [0s, 1d].
    scaleDownFactor : float, default is Undefined, optional
        Fraction of average pending memory in the last cooldown period for which to
        remove workers. A scale-down factor of 1 will result in scaling down so that there
        is no available memory remaining after the update (more aggressive scaling).
        A scale-down factor of 0 disables removing workers, which can be beneficial for
        autoscaling a single job.
        Bounds: [0.0, 1.0].
    scaleDownMinWorkerFraction : float, default is Undefined, optional
        Minimum scale-down threshold as a fraction of total cluster size before scaling occurs.
        For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler must
        recommend at least a 2 worker scale-down for the cluster to scale. A threshold of 0
        means the autoscaler will scale down on any recommended change.
        Bounds: [0.0, 1.0]. Default: 0.0.
    scaleUpFactor : float, default is Undefined, optional
        Fraction of average pending memory in the last cooldown period for which to
        add workers. A scale-up factor of 1.0 will result in scaling up so that there
        is no pending memory remaining after the update (more aggressive scaling).
        A scale-up factor closer to 0 will result in a smaller magnitude of scaling up
        (less aggressive scaling).
        Bounds: [0.0, 1.0].
    scaleUpMinWorkerFraction : float, default is Undefined, optional
        Minimum scale-up threshold as a fraction of total cluster size before scaling
        occurs. For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler
        must recommend at least a 2-worker scale-up for the cluster to scale. A threshold of
        0 means the autoscaler will scale up on any recommended change.
        Bounds: [0.0, 1.0]. Default: 0.0.
    """


    gracefulDecommissionTimeout?: str

    scaleDownFactor?: float

    scaleDownMinWorkerFraction?: float

    scaleUpFactor?: float

    scaleUpMinWorkerFraction?: float


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatusAtProviderSecondaryWorkerConfigItems0:
    """
    dataproc gcp upbound io v1beta1 autoscaling policy status at provider secondary worker config items0

    Attributes
    ----------
    maxInstances : float, default is Undefined, optional
        Maximum number of instances for this group. Note that by default, clusters will not use
        secondary workers. Required for secondary workers if the minimum secondary instances is set.
        Bounds: [minInstances, ). Defaults to 0.
    minInstances : float, default is Undefined, optional
        Minimum number of instances for this group. Bounds: [0, maxInstances]. Defaults to 0.
    weight : float, default is Undefined, optional
        Weight for the instance group, which is used to determine the fraction of total workers
        in the cluster from this instance group. For example, if primary workers have weight 2,
        and secondary workers have weight 1, the cluster will have approximately 2 primary workers
        for each secondary worker.
        The cluster may not reach the specified balance if constrained by min/max bounds or other
        autoscaling settings. For example, if maxInstances for secondary workers is 0, then only
        primary workers will be added. The cluster can also be out of balance when created.
        If weight is not set on any instance group, the cluster will default to equal weight for
        all groups: the cluster will attempt to maintain an equal number of workers in each group
        within the configured size bounds for each group. If weight is set for one group only,
        the cluster will default to zero weight on the unset group. For example if weight is set
        only on primary workers, the cluster will use primary workers only and no secondary workers.
    """


    maxInstances?: float

    minInstances?: float

    weight?: float


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatusAtProviderWorkerConfigItems0:
    """
    dataproc gcp upbound io v1beta1 autoscaling policy status at provider worker config items0

    Attributes
    ----------
    maxInstances : float, default is Undefined, optional
        Maximum number of instances for this group.
    minInstances : float, default is Undefined, optional
        Minimum number of instances for this group. Bounds: [2, maxInstances]. Defaults to 2.
    weight : float, default is Undefined, optional
        Weight for the instance group, which is used to determine the fraction of total workers
        in the cluster from this instance group. For example, if primary workers have weight 2,
        and secondary workers have weight 1, the cluster will have approximately 2 primary workers
        for each secondary worker.
        The cluster may not reach the specified balance if constrained by min/max bounds or other
        autoscaling settings. For example, if maxInstances for secondary workers is 0, then only
        primary workers will be added. The cluster can also be out of balance when created.
        If weight is not set on any instance group, the cluster will default to equal weight for
        all groups: the cluster will attempt to maintain an equal number of workers in each group
        within the configured size bounds for each group. If weight is set for one group only,
        the cluster will default to zero weight on the unset group. For example if weight is set
        only on primary workers, the cluster will use primary workers only and no secondary workers.
    """


    maxInstances?: float

    minInstances?: float

    weight?: float


schema DataprocGcpUpboundIoV1beta1AutoscalingPolicyStatusConditionsItems0:
    """
    A Condition that may apply to a resource.

    Attributes
    ----------
    lastTransitionTime : str, default is Undefined, required
        LastTransitionTime is the last time this condition transitioned from one
        status to another.
    message : str, default is Undefined, optional
        A Message containing details about this condition's last transition from
        one status to another, if any.
    reason : str, default is Undefined, required
        A Reason for this condition's last transition from one status to another.
    status : str, default is Undefined, required
        Status of this condition; is it currently True, False, or Unknown?
    $type : str, default is Undefined, required
        Type of this condition. At most one of each condition type may apply to
        a resource at any point in time.
    """


    lastTransitionTime: str

    message?: str

    reason: str

    status: str

    $type: str


